{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.special import logit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regiocode</th>\n",
       "      <th>Population</th>\n",
       "      <th>Immigrants</th>\n",
       "      <th>Social benefits</th>\n",
       "      <th>Homeprice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Bankruptcy</th>\n",
       "      <th>Population Density</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Laborforce</th>\n",
       "      <th>Electionresult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1680</td>\n",
       "      <td>1.068825</td>\n",
       "      <td>10.282956</td>\n",
       "      <td>-1.869934</td>\n",
       "      <td>24.823141</td>\n",
       "      <td>5.813264</td>\n",
       "      <td>22.333913</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>2.235031</td>\n",
       "      <td>-0.339541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G1959</td>\n",
       "      <td>0.695107</td>\n",
       "      <td>6.231074</td>\n",
       "      <td>0.202074</td>\n",
       "      <td>16.540965</td>\n",
       "      <td>5.210921</td>\n",
       "      <td>22.075703</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>2.584089</td>\n",
       "      <td>-0.567556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G0358</td>\n",
       "      <td>0.403693</td>\n",
       "      <td>2.781515</td>\n",
       "      <td>-0.132528</td>\n",
       "      <td>26.465343</td>\n",
       "      <td>5.836617</td>\n",
       "      <td>19.932434</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>-7.166212</td>\n",
       "      <td>1.628950</td>\n",
       "      <td>-0.522940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G0197</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>-0.195520</td>\n",
       "      <td>1.157618</td>\n",
       "      <td>25.154637</td>\n",
       "      <td>5.755499</td>\n",
       "      <td>17.593361</td>\n",
       "      <td>853.0</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>2.778095</td>\n",
       "      <td>-0.507016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G0569</td>\n",
       "      <td>-0.366356</td>\n",
       "      <td>-0.247573</td>\n",
       "      <td>-0.251652</td>\n",
       "      <td>25.901639</td>\n",
       "      <td>5.690203</td>\n",
       "      <td>22.287009</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>1.987726</td>\n",
       "      <td>-0.602941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>G0637</td>\n",
       "      <td>0.328183</td>\n",
       "      <td>1.469634</td>\n",
       "      <td>3.966928</td>\n",
       "      <td>-1.656670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.923668</td>\n",
       "      <td>3540.0</td>\n",
       "      <td>17.628205</td>\n",
       "      <td>0.426136</td>\n",
       "      <td>0.199025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>G0638</td>\n",
       "      <td>0.326062</td>\n",
       "      <td>1.876911</td>\n",
       "      <td>2.266697</td>\n",
       "      <td>-2.539691</td>\n",
       "      <td>0.256396</td>\n",
       "      <td>1.923668</td>\n",
       "      <td>384.0</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>-1.051254</td>\n",
       "      <td>0.390655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>G1730</td>\n",
       "      <td>-0.078499</td>\n",
       "      <td>2.002775</td>\n",
       "      <td>0.941794</td>\n",
       "      <td>-1.339607</td>\n",
       "      <td>0.672403</td>\n",
       "      <td>13.509308</td>\n",
       "      <td>225.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.632716</td>\n",
       "      <td>0.185393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>G0879</td>\n",
       "      <td>0.465212</td>\n",
       "      <td>2.192951</td>\n",
       "      <td>1.874646</td>\n",
       "      <td>-2.051091</td>\n",
       "      <td>0.424127</td>\n",
       "      <td>13.301216</td>\n",
       "      <td>176.0</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>-0.176624</td>\n",
       "      <td>0.503244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>G0193</td>\n",
       "      <td>1.043475</td>\n",
       "      <td>1.800324</td>\n",
       "      <td>2.204826</td>\n",
       "      <td>-1.575706</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>12.553296</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>-0.302746</td>\n",
       "      <td>0.219409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1780 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Regiocode  Population  Immigrants  Social benefits  Homeprice    Income  \\\n",
       "0       G1680    1.068825   10.282956        -1.869934  24.823141  5.813264   \n",
       "1       G1959    0.695107    6.231074         0.202074  16.540965  5.210921   \n",
       "2       G0358    0.403693    2.781515        -0.132528  26.465343  5.836617   \n",
       "3       G0197    0.079268   -0.195520         1.157618  25.154637  5.755499   \n",
       "4       G0569   -0.366356   -0.247573        -0.251652  25.901639  5.690203   \n",
       "..        ...         ...         ...              ...        ...       ...   \n",
       "351     G0637    0.328183    1.469634         3.966928  -1.656670  0.000000   \n",
       "352     G0638    0.326062    1.876911         2.266697  -2.539691  0.256396   \n",
       "353     G1730   -0.078499    2.002775         0.941794  -1.339607  0.672403   \n",
       "354     G0879    0.465212    2.192951         1.874646  -2.051091  0.424127   \n",
       "355     G0193    1.043475    1.800324         2.204826  -1.575706  0.602410   \n",
       "\n",
       "     Bankruptcy  Population Density  Unemployment  Laborforce  Electionresult  \n",
       "0     22.333913                92.0    -15.000000    2.235031       -0.339541  \n",
       "1     22.075703               775.0      0.793651    2.584089       -0.567556  \n",
       "2     19.932434              1057.0     -7.166212    1.628950       -0.522940  \n",
       "3     17.593361               853.0     -2.857143    2.778095       -0.507016  \n",
       "4     22.287009              1043.0     13.888889    1.987726       -0.602941  \n",
       "..          ...                 ...           ...         ...             ...  \n",
       "351    1.923668              3540.0     17.628205    0.426136        0.199025  \n",
       "352    1.923668               384.0      6.111111   -1.051254        0.390655  \n",
       "353   13.509308               225.0     25.000000    0.632716        0.185393  \n",
       "354   13.301216               176.0      6.875000   -0.176624        0.503244  \n",
       "355   12.553296              1091.0     12.500000   -0.302746        0.219409  \n",
       "\n",
       "[1780 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length X_train: 1780\n",
      "Length y_train: 1780\n",
      "Length X_test: 356\n",
      "Length y_test: 356\n",
      "[[0.36508568 0.79154104 0.96643634 0.3624417  0.55134364]\n",
      " [0.40962339 0.71988625 0.95967766 0.36012095 0.56833568]\n",
      " [0.40243114 0.80574885 0.96669837 0.3408575  0.52183975]\n",
      " ...\n",
      " [0.42552364 0.56518917 0.90875254 0.28312719 0.47334338]\n",
      " [0.44557527 0.55903363 0.90596671 0.28125689 0.43394495]\n",
      " [0.45267247 0.56314651 0.90796716 0.27453467 0.42780533]]\n",
      "0     -0.339541\n",
      "1     -0.567556\n",
      "2     -0.522940\n",
      "3     -0.507016\n",
      "4     -0.602941\n",
      "         ...   \n",
      "351    0.199025\n",
      "352    0.390655\n",
      "353    0.185393\n",
      "354    0.503244\n",
      "355    0.219409\n",
      "Name: Electionresult, Length: 1780, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "display(df)\n",
    "X_train = df[[\"Social benefits\",\"Homeprice\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_train = df[\"Electionresult\"]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test =  dftest[[\"Social benefits\",\"Homeprice\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_test = dftest[\"Electionresult\"]\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"Length X_train:\",len(X_train))\n",
    "print(\"Length y_train:\",len(y_train))\n",
    "\n",
    "print(\"Length X_test:\",len(X_test))\n",
    "print(\"Length y_test:\",len(y_test))\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (7, 2), (7, 3), (7, 4), (7, 5), (7, 6), (7, 7), (7, 8), (7, 9), (7, 10), (8, 2), (8, 3), (8, 4), (8, 5), (8, 6), (8, 7), (8, 8), (8, 9), (8, 10), (9, 2), (9, 3), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9), (9, 10), (10, 2), (10, 3), (10, 4), (10, 5), (10, 6), (10, 7), (10, 8), (10, 9), (10, 10), (2, 2, 2), (2, 2, 3), (2, 2, 4), (2, 2, 5), (2, 2, 6), (2, 2, 7), (2, 2, 8), (2, 2, 9), (2, 2, 10), (2, 3, 2), (2, 3, 3), (2, 3, 4), (2, 3, 5), (2, 3, 6), (2, 3, 7), (2, 3, 8), (2, 3, 9), (2, 3, 10), (2, 4, 2), (2, 4, 3), (2, 4, 4), (2, 4, 5), (2, 4, 6), (2, 4, 7), (2, 4, 8), (2, 4, 9), (2, 4, 10), (2, 5, 2), (2, 5, 3), (2, 5, 4), (2, 5, 5), (2, 5, 6), (2, 5, 7), (2, 5, 8), (2, 5, 9), (2, 5, 10), (2, 6, 2), (2, 6, 3), (2, 6, 4), (2, 6, 5), (2, 6, 6), (2, 6, 7), (2, 6, 8), (2, 6, 9), (2, 6, 10), (2, 7, 2), (2, 7, 3), (2, 7, 4), (2, 7, 5), (2, 7, 6), (2, 7, 7), (2, 7, 8), (2, 7, 9), (2, 7, 10), (2, 8, 2), (2, 8, 3), (2, 8, 4), (2, 8, 5), (2, 8, 6), (2, 8, 7), (2, 8, 8), (2, 8, 9), (2, 8, 10), (2, 9, 2), (2, 9, 3), (2, 9, 4), (2, 9, 5), (2, 9, 6), (2, 9, 7), (2, 9, 8), (2, 9, 9), (2, 9, 10), (2, 10, 2), (2, 10, 3), (2, 10, 4), (2, 10, 5), (2, 10, 6), (2, 10, 7), (2, 10, 8), (2, 10, 9), (2, 10, 10), (3, 2, 2), (3, 2, 3), (3, 2, 4), (3, 2, 5), (3, 2, 6), (3, 2, 7), (3, 2, 8), (3, 2, 9), (3, 2, 10), (3, 3, 2), (3, 3, 3), (3, 3, 4), (3, 3, 5), (3, 3, 6), (3, 3, 7), (3, 3, 8), (3, 3, 9), (3, 3, 10), (3, 4, 2), (3, 4, 3), (3, 4, 4), (3, 4, 5), (3, 4, 6), (3, 4, 7), (3, 4, 8), (3, 4, 9), (3, 4, 10), (3, 5, 2), (3, 5, 3), (3, 5, 4), (3, 5, 5), (3, 5, 6), (3, 5, 7), (3, 5, 8), (3, 5, 9), (3, 5, 10), (3, 6, 2), (3, 6, 3), (3, 6, 4), (3, 6, 5), (3, 6, 6), (3, 6, 7), (3, 6, 8), (3, 6, 9), (3, 6, 10), (3, 7, 2), (3, 7, 3), (3, 7, 4), (3, 7, 5), (3, 7, 6), (3, 7, 7), (3, 7, 8), (3, 7, 9), (3, 7, 10), (3, 8, 2), (3, 8, 3), (3, 8, 4), (3, 8, 5), (3, 8, 6), (3, 8, 7), (3, 8, 8), (3, 8, 9), (3, 8, 10), (3, 9, 2), (3, 9, 3), (3, 9, 4), (3, 9, 5), (3, 9, 6), (3, 9, 7), (3, 9, 8), (3, 9, 9), (3, 9, 10), (3, 10, 2), (3, 10, 3), (3, 10, 4), (3, 10, 5), (3, 10, 6), (3, 10, 7), (3, 10, 8), (3, 10, 9), (3, 10, 10), (4, 2, 2), (4, 2, 3), (4, 2, 4), (4, 2, 5), (4, 2, 6), (4, 2, 7), (4, 2, 8), (4, 2, 9), (4, 2, 10), (4, 3, 2), (4, 3, 3), (4, 3, 4), (4, 3, 5), (4, 3, 6), (4, 3, 7), (4, 3, 8), (4, 3, 9), (4, 3, 10), (4, 4, 2), (4, 4, 3), (4, 4, 4), (4, 4, 5), (4, 4, 6), (4, 4, 7), (4, 4, 8), (4, 4, 9), (4, 4, 10), (4, 5, 2), (4, 5, 3), (4, 5, 4), (4, 5, 5), (4, 5, 6), (4, 5, 7), (4, 5, 8), (4, 5, 9), (4, 5, 10), (4, 6, 2), (4, 6, 3), (4, 6, 4), (4, 6, 5), (4, 6, 6), (4, 6, 7), (4, 6, 8), (4, 6, 9), (4, 6, 10), (4, 7, 2), (4, 7, 3), (4, 7, 4), (4, 7, 5), (4, 7, 6), (4, 7, 7), (4, 7, 8), (4, 7, 9), (4, 7, 10), (4, 8, 2), (4, 8, 3), (4, 8, 4), (4, 8, 5), (4, 8, 6), (4, 8, 7), (4, 8, 8), (4, 8, 9), (4, 8, 10), (4, 9, 2), (4, 9, 3), (4, 9, 4), (4, 9, 5), (4, 9, 6), (4, 9, 7), (4, 9, 8), (4, 9, 9), (4, 9, 10), (4, 10, 2), (4, 10, 3), (4, 10, 4), (4, 10, 5), (4, 10, 6), (4, 10, 7), (4, 10, 8), (4, 10, 9), (4, 10, 10), (5, 2, 2), (5, 2, 3), (5, 2, 4), (5, 2, 5), (5, 2, 6), (5, 2, 7), (5, 2, 8), (5, 2, 9), (5, 2, 10), (5, 3, 2), (5, 3, 3), (5, 3, 4), (5, 3, 5), (5, 3, 6), (5, 3, 7), (5, 3, 8), (5, 3, 9), (5, 3, 10), (5, 4, 2), (5, 4, 3), (5, 4, 4), (5, 4, 5), (5, 4, 6), (5, 4, 7), (5, 4, 8), (5, 4, 9), (5, 4, 10), (5, 5, 2), (5, 5, 3), (5, 5, 4), (5, 5, 5), (5, 5, 6), (5, 5, 7), (5, 5, 8), (5, 5, 9), (5, 5, 10), (5, 6, 2), (5, 6, 3), (5, 6, 4), (5, 6, 5), (5, 6, 6), (5, 6, 7), (5, 6, 8), (5, 6, 9), (5, 6, 10), (5, 7, 2), (5, 7, 3), (5, 7, 4), (5, 7, 5), (5, 7, 6), (5, 7, 7), (5, 7, 8), (5, 7, 9), (5, 7, 10), (5, 8, 2), (5, 8, 3), (5, 8, 4), (5, 8, 5), (5, 8, 6), (5, 8, 7), (5, 8, 8), (5, 8, 9), (5, 8, 10), (5, 9, 2), (5, 9, 3), (5, 9, 4), (5, 9, 5), (5, 9, 6), (5, 9, 7), (5, 9, 8), (5, 9, 9), (5, 9, 10), (5, 10, 2), (5, 10, 3), (5, 10, 4), (5, 10, 5), (5, 10, 6), (5, 10, 7), (5, 10, 8), (5, 10, 9), (5, 10, 10), (6, 2, 2), (6, 2, 3), (6, 2, 4), (6, 2, 5), (6, 2, 6), (6, 2, 7), (6, 2, 8), (6, 2, 9), (6, 2, 10), (6, 3, 2), (6, 3, 3), (6, 3, 4), (6, 3, 5), (6, 3, 6), (6, 3, 7), (6, 3, 8), (6, 3, 9), (6, 3, 10), (6, 4, 2), (6, 4, 3), (6, 4, 4), (6, 4, 5), (6, 4, 6), (6, 4, 7), (6, 4, 8), (6, 4, 9), (6, 4, 10), (6, 5, 2), (6, 5, 3), (6, 5, 4), (6, 5, 5), (6, 5, 6), (6, 5, 7), (6, 5, 8), (6, 5, 9), (6, 5, 10), (6, 6, 2), (6, 6, 3), (6, 6, 4), (6, 6, 5), (6, 6, 6), (6, 6, 7), (6, 6, 8), (6, 6, 9), (6, 6, 10), (6, 7, 2), (6, 7, 3), (6, 7, 4), (6, 7, 5), (6, 7, 6), (6, 7, 7), (6, 7, 8), (6, 7, 9), (6, 7, 10), (6, 8, 2), (6, 8, 3), (6, 8, 4), (6, 8, 5), (6, 8, 6), (6, 8, 7), (6, 8, 8), (6, 8, 9), (6, 8, 10), (6, 9, 2), (6, 9, 3), (6, 9, 4), (6, 9, 5), (6, 9, 6), (6, 9, 7), (6, 9, 8), (6, 9, 9), (6, 9, 10), (6, 10, 2), (6, 10, 3), (6, 10, 4), (6, 10, 5), (6, 10, 6), (6, 10, 7), (6, 10, 8), (6, 10, 9), (6, 10, 10), (7, 2, 2), (7, 2, 3), (7, 2, 4), (7, 2, 5), (7, 2, 6), (7, 2, 7), (7, 2, 8), (7, 2, 9), (7, 2, 10), (7, 3, 2), (7, 3, 3), (7, 3, 4), (7, 3, 5), (7, 3, 6), (7, 3, 7), (7, 3, 8), (7, 3, 9), (7, 3, 10), (7, 4, 2), (7, 4, 3), (7, 4, 4), (7, 4, 5), (7, 4, 6), (7, 4, 7), (7, 4, 8), (7, 4, 9), (7, 4, 10), (7, 5, 2), (7, 5, 3), (7, 5, 4), (7, 5, 5), (7, 5, 6), (7, 5, 7), (7, 5, 8), (7, 5, 9), (7, 5, 10), (7, 6, 2), (7, 6, 3), (7, 6, 4), (7, 6, 5), (7, 6, 6), (7, 6, 7), (7, 6, 8), (7, 6, 9), (7, 6, 10), (7, 7, 2), (7, 7, 3), (7, 7, 4), (7, 7, 5), (7, 7, 6), (7, 7, 7), (7, 7, 8), (7, 7, 9), (7, 7, 10), (7, 8, 2), (7, 8, 3), (7, 8, 4), (7, 8, 5), (7, 8, 6), (7, 8, 7), (7, 8, 8), (7, 8, 9), (7, 8, 10), (7, 9, 2), (7, 9, 3), (7, 9, 4), (7, 9, 5), (7, 9, 6), (7, 9, 7), (7, 9, 8), (7, 9, 9), (7, 9, 10), (7, 10, 2), (7, 10, 3), (7, 10, 4), (7, 10, 5), (7, 10, 6), (7, 10, 7), (7, 10, 8), (7, 10, 9), (7, 10, 10), (8, 2, 2), (8, 2, 3), (8, 2, 4), (8, 2, 5), (8, 2, 6), (8, 2, 7), (8, 2, 8), (8, 2, 9), (8, 2, 10), (8, 3, 2), (8, 3, 3), (8, 3, 4), (8, 3, 5), (8, 3, 6), (8, 3, 7), (8, 3, 8), (8, 3, 9), (8, 3, 10), (8, 4, 2), (8, 4, 3), (8, 4, 4), (8, 4, 5), (8, 4, 6), (8, 4, 7), (8, 4, 8), (8, 4, 9), (8, 4, 10), (8, 5, 2), (8, 5, 3), (8, 5, 4), (8, 5, 5), (8, 5, 6), (8, 5, 7), (8, 5, 8), (8, 5, 9), (8, 5, 10), (8, 6, 2), (8, 6, 3), (8, 6, 4), (8, 6, 5), (8, 6, 6), (8, 6, 7), (8, 6, 8), (8, 6, 9), (8, 6, 10), (8, 7, 2), (8, 7, 3), (8, 7, 4), (8, 7, 5), (8, 7, 6), (8, 7, 7), (8, 7, 8), (8, 7, 9), (8, 7, 10), (8, 8, 2), (8, 8, 3), (8, 8, 4), (8, 8, 5), (8, 8, 6), (8, 8, 7), (8, 8, 8), (8, 8, 9), (8, 8, 10), (8, 9, 2), (8, 9, 3), (8, 9, 4), (8, 9, 5), (8, 9, 6), (8, 9, 7), (8, 9, 8), (8, 9, 9), (8, 9, 10), (8, 10, 2), (8, 10, 3), (8, 10, 4), (8, 10, 5), (8, 10, 6), (8, 10, 7), (8, 10, 8), (8, 10, 9), (8, 10, 10), (9, 2, 2), (9, 2, 3), (9, 2, 4), (9, 2, 5), (9, 2, 6), (9, 2, 7), (9, 2, 8), (9, 2, 9), (9, 2, 10), (9, 3, 2), (9, 3, 3), (9, 3, 4), (9, 3, 5), (9, 3, 6), (9, 3, 7), (9, 3, 8), (9, 3, 9), (9, 3, 10), (9, 4, 2), (9, 4, 3), (9, 4, 4), (9, 4, 5), (9, 4, 6), (9, 4, 7), (9, 4, 8), (9, 4, 9), (9, 4, 10), (9, 5, 2), (9, 5, 3), (9, 5, 4), (9, 5, 5), (9, 5, 6), (9, 5, 7), (9, 5, 8), (9, 5, 9), (9, 5, 10), (9, 6, 2), (9, 6, 3), (9, 6, 4), (9, 6, 5), (9, 6, 6), (9, 6, 7), (9, 6, 8), (9, 6, 9), (9, 6, 10), (9, 7, 2), (9, 7, 3), (9, 7, 4), (9, 7, 5), (9, 7, 6), (9, 7, 7), (9, 7, 8), (9, 7, 9), (9, 7, 10), (9, 8, 2), (9, 8, 3), (9, 8, 4), (9, 8, 5), (9, 8, 6), (9, 8, 7), (9, 8, 8), (9, 8, 9), (9, 8, 10), (9, 9, 2), (9, 9, 3), (9, 9, 4), (9, 9, 5), (9, 9, 6), (9, 9, 7), (9, 9, 8), (9, 9, 9), (9, 9, 10), (9, 10, 2), (9, 10, 3), (9, 10, 4), (9, 10, 5), (9, 10, 6), (9, 10, 7), (9, 10, 8), (9, 10, 9), (9, 10, 10), (10, 2, 2), (10, 2, 3), (10, 2, 4), (10, 2, 5), (10, 2, 6), (10, 2, 7), (10, 2, 8), (10, 2, 9), (10, 2, 10), (10, 3, 2), (10, 3, 3), (10, 3, 4), (10, 3, 5), (10, 3, 6), (10, 3, 7), (10, 3, 8), (10, 3, 9), (10, 3, 10), (10, 4, 2), (10, 4, 3), (10, 4, 4), (10, 4, 5), (10, 4, 6), (10, 4, 7), (10, 4, 8), (10, 4, 9), (10, 4, 10), (10, 5, 2), (10, 5, 3), (10, 5, 4), (10, 5, 5), (10, 5, 6), (10, 5, 7), (10, 5, 8), (10, 5, 9), (10, 5, 10), (10, 6, 2), (10, 6, 3), (10, 6, 4), (10, 6, 5), (10, 6, 6), (10, 6, 7), (10, 6, 8), (10, 6, 9), (10, 6, 10), (10, 7, 2), (10, 7, 3), (10, 7, 4), (10, 7, 5), (10, 7, 6), (10, 7, 7), (10, 7, 8), (10, 7, 9), (10, 7, 10), (10, 8, 2), (10, 8, 3), (10, 8, 4), (10, 8, 5), (10, 8, 6), (10, 8, 7), (10, 8, 8), (10, 8, 9), (10, 8, 10), (10, 9, 2), (10, 9, 3), (10, 9, 4), (10, 9, 5), (10, 9, 6), (10, 9, 7), (10, 9, 8), (10, 9, 9), (10, 9, 10), (10, 10, 2), (10, 10, 3), (10, 10, 4), (10, 10, 5), (10, 10, 6), (10, 10, 7), (10, 10, 8), (10, 10, 9), (10, 10, 10), (20, 20), (20, 30), (20, 40), (20, 50), (20, 60), (20, 70), (20, 80), (20, 90), (30, 20), (30, 30), (30, 40), (30, 50), (30, 60), (30, 70), (30, 80), (30, 90), (40, 20), (40, 30), (40, 40), (40, 50), (40, 60), (40, 70), (40, 80), (40, 90), (50, 20), (50, 30), (50, 40), (50, 50), (50, 60), (50, 70), (50, 80), (50, 90), (60, 20), (60, 30), (60, 40), (60, 50), (60, 60), (60, 70), (60, 80), (60, 90), (70, 20), (70, 30), (70, 40), (70, 50), (70, 60), (70, 70), (70, 80), (70, 90), (80, 20), (80, 30), (80, 40), (80, 50), (80, 60), (80, 70), (80, 80), (80, 90), (90, 20), (90, 30), (90, 40), (90, 50), (90, 60), (90, 70), (90, 80), (90, 90), (20, 20, 20), (20, 20, 30), (20, 20, 40), (20, 20, 50), (20, 20, 60), (20, 20, 70), (20, 20, 80), (20, 20, 90), (20, 30, 20), (20, 30, 30), (20, 30, 40), (20, 30, 50), (20, 30, 60), (20, 30, 70), (20, 30, 80), (20, 30, 90), (20, 40, 20), (20, 40, 30), (20, 40, 40), (20, 40, 50), (20, 40, 60), (20, 40, 70), (20, 40, 80), (20, 40, 90), (20, 50, 20), (20, 50, 30), (20, 50, 40), (20, 50, 50), (20, 50, 60), (20, 50, 70), (20, 50, 80), (20, 50, 90), (20, 60, 20), (20, 60, 30), (20, 60, 40), (20, 60, 50), (20, 60, 60), (20, 60, 70), (20, 60, 80), (20, 60, 90), (20, 70, 20), (20, 70, 30), (20, 70, 40), (20, 70, 50), (20, 70, 60), (20, 70, 70), (20, 70, 80), (20, 70, 90), (20, 80, 20), (20, 80, 30), (20, 80, 40), (20, 80, 50), (20, 80, 60), (20, 80, 70), (20, 80, 80), (20, 80, 90), (20, 90, 20), (20, 90, 30), (20, 90, 40), (20, 90, 50), (20, 90, 60), (20, 90, 70), (20, 90, 80), (20, 90, 90), (30, 20, 20), (30, 20, 30), (30, 20, 40), (30, 20, 50), (30, 20, 60), (30, 20, 70), (30, 20, 80), (30, 20, 90), (30, 30, 20), (30, 30, 30), (30, 30, 40), (30, 30, 50), (30, 30, 60), (30, 30, 70), (30, 30, 80), (30, 30, 90), (30, 40, 20), (30, 40, 30), (30, 40, 40), (30, 40, 50), (30, 40, 60), (30, 40, 70), (30, 40, 80), (30, 40, 90), (30, 50, 20), (30, 50, 30), (30, 50, 40), (30, 50, 50), (30, 50, 60), (30, 50, 70), (30, 50, 80), (30, 50, 90), (30, 60, 20), (30, 60, 30), (30, 60, 40), (30, 60, 50), (30, 60, 60), (30, 60, 70), (30, 60, 80), (30, 60, 90), (30, 70, 20), (30, 70, 30), (30, 70, 40), (30, 70, 50), (30, 70, 60), (30, 70, 70), (30, 70, 80), (30, 70, 90), (30, 80, 20), (30, 80, 30), (30, 80, 40), (30, 80, 50), (30, 80, 60), (30, 80, 70), (30, 80, 80), (30, 80, 90), (30, 90, 20), (30, 90, 30), (30, 90, 40), (30, 90, 50), (30, 90, 60), (30, 90, 70), (30, 90, 80), (30, 90, 90), (40, 20, 20), (40, 20, 30), (40, 20, 40), (40, 20, 50), (40, 20, 60), (40, 20, 70), (40, 20, 80), (40, 20, 90), (40, 30, 20), (40, 30, 30), (40, 30, 40), (40, 30, 50), (40, 30, 60), (40, 30, 70), (40, 30, 80), (40, 30, 90), (40, 40, 20), (40, 40, 30), (40, 40, 40), (40, 40, 50), (40, 40, 60), (40, 40, 70), (40, 40, 80), (40, 40, 90), (40, 50, 20), (40, 50, 30), (40, 50, 40), (40, 50, 50), (40, 50, 60), (40, 50, 70), (40, 50, 80), (40, 50, 90), (40, 60, 20), (40, 60, 30), (40, 60, 40), (40, 60, 50), (40, 60, 60), (40, 60, 70), (40, 60, 80), (40, 60, 90), (40, 70, 20), (40, 70, 30), (40, 70, 40), (40, 70, 50), (40, 70, 60), (40, 70, 70), (40, 70, 80), (40, 70, 90), (40, 80, 20), (40, 80, 30), (40, 80, 40), (40, 80, 50), (40, 80, 60), (40, 80, 70), (40, 80, 80), (40, 80, 90), (40, 90, 20), (40, 90, 30), (40, 90, 40), (40, 90, 50), (40, 90, 60), (40, 90, 70), (40, 90, 80), (40, 90, 90), (50, 20, 20), (50, 20, 30), (50, 20, 40), (50, 20, 50), (50, 20, 60), (50, 20, 70), (50, 20, 80), (50, 20, 90), (50, 30, 20), (50, 30, 30), (50, 30, 40), (50, 30, 50), (50, 30, 60), (50, 30, 70), (50, 30, 80), (50, 30, 90), (50, 40, 20), (50, 40, 30), (50, 40, 40), (50, 40, 50), (50, 40, 60), (50, 40, 70), (50, 40, 80), (50, 40, 90), (50, 50, 20), (50, 50, 30), (50, 50, 40), (50, 50, 50), (50, 50, 60), (50, 50, 70), (50, 50, 80), (50, 50, 90), (50, 60, 20), (50, 60, 30), (50, 60, 40), (50, 60, 50), (50, 60, 60), (50, 60, 70), (50, 60, 80), (50, 60, 90), (50, 70, 20), (50, 70, 30), (50, 70, 40), (50, 70, 50), (50, 70, 60), (50, 70, 70), (50, 70, 80), (50, 70, 90), (50, 80, 20), (50, 80, 30), (50, 80, 40), (50, 80, 50), (50, 80, 60), (50, 80, 70), (50, 80, 80), (50, 80, 90), (50, 90, 20), (50, 90, 30), (50, 90, 40), (50, 90, 50), (50, 90, 60), (50, 90, 70), (50, 90, 80), (50, 90, 90), (60, 20, 20), (60, 20, 30), (60, 20, 40), (60, 20, 50), (60, 20, 60), (60, 20, 70), (60, 20, 80), (60, 20, 90), (60, 30, 20), (60, 30, 30), (60, 30, 40), (60, 30, 50), (60, 30, 60), (60, 30, 70), (60, 30, 80), (60, 30, 90), (60, 40, 20), (60, 40, 30), (60, 40, 40), (60, 40, 50), (60, 40, 60), (60, 40, 70), (60, 40, 80), (60, 40, 90), (60, 50, 20), (60, 50, 30), (60, 50, 40), (60, 50, 50), (60, 50, 60), (60, 50, 70), (60, 50, 80), (60, 50, 90), (60, 60, 20), (60, 60, 30), (60, 60, 40), (60, 60, 50), (60, 60, 60), (60, 60, 70), (60, 60, 80), (60, 60, 90), (60, 70, 20), (60, 70, 30), (60, 70, 40), (60, 70, 50), (60, 70, 60), (60, 70, 70), (60, 70, 80), (60, 70, 90), (60, 80, 20), (60, 80, 30), (60, 80, 40), (60, 80, 50), (60, 80, 60), (60, 80, 70), (60, 80, 80), (60, 80, 90), (60, 90, 20), (60, 90, 30), (60, 90, 40), (60, 90, 50), (60, 90, 60), (60, 90, 70), (60, 90, 80), (60, 90, 90), (70, 20, 20), (70, 20, 30), (70, 20, 40), (70, 20, 50), (70, 20, 60), (70, 20, 70), (70, 20, 80), (70, 20, 90), (70, 30, 20), (70, 30, 30), (70, 30, 40), (70, 30, 50), (70, 30, 60), (70, 30, 70), (70, 30, 80), (70, 30, 90), (70, 40, 20), (70, 40, 30), (70, 40, 40), (70, 40, 50), (70, 40, 60), (70, 40, 70), (70, 40, 80), (70, 40, 90), (70, 50, 20), (70, 50, 30), (70, 50, 40), (70, 50, 50), (70, 50, 60), (70, 50, 70), (70, 50, 80), (70, 50, 90), (70, 60, 20), (70, 60, 30), (70, 60, 40), (70, 60, 50), (70, 60, 60), (70, 60, 70), (70, 60, 80), (70, 60, 90), (70, 70, 20), (70, 70, 30), (70, 70, 40), (70, 70, 50), (70, 70, 60), (70, 70, 70), (70, 70, 80), (70, 70, 90), (70, 80, 20), (70, 80, 30), (70, 80, 40), (70, 80, 50), (70, 80, 60), (70, 80, 70), (70, 80, 80), (70, 80, 90), (70, 90, 20), (70, 90, 30), (70, 90, 40), (70, 90, 50), (70, 90, 60), (70, 90, 70), (70, 90, 80), (70, 90, 90), (80, 20, 20), (80, 20, 30), (80, 20, 40), (80, 20, 50), (80, 20, 60), (80, 20, 70), (80, 20, 80), (80, 20, 90), (80, 30, 20), (80, 30, 30), (80, 30, 40), (80, 30, 50), (80, 30, 60), (80, 30, 70), (80, 30, 80), (80, 30, 90), (80, 40, 20), (80, 40, 30), (80, 40, 40), (80, 40, 50), (80, 40, 60), (80, 40, 70), (80, 40, 80), (80, 40, 90), (80, 50, 20), (80, 50, 30), (80, 50, 40), (80, 50, 50), (80, 50, 60), (80, 50, 70), (80, 50, 80), (80, 50, 90), (80, 60, 20), (80, 60, 30), (80, 60, 40), (80, 60, 50), (80, 60, 60), (80, 60, 70), (80, 60, 80), (80, 60, 90), (80, 70, 20), (80, 70, 30), (80, 70, 40), (80, 70, 50), (80, 70, 60), (80, 70, 70), (80, 70, 80), (80, 70, 90), (80, 80, 20), (80, 80, 30), (80, 80, 40), (80, 80, 50), (80, 80, 60), (80, 80, 70), (80, 80, 80), (80, 80, 90), (80, 90, 20), (80, 90, 30), (80, 90, 40), (80, 90, 50), (80, 90, 60), (80, 90, 70), (80, 90, 80), (80, 90, 90), (90, 20, 20), (90, 20, 30), (90, 20, 40), (90, 20, 50), (90, 20, 60), (90, 20, 70), (90, 20, 80), (90, 20, 90), (90, 30, 20), (90, 30, 30), (90, 30, 40), (90, 30, 50), (90, 30, 60), (90, 30, 70), (90, 30, 80), (90, 30, 90), (90, 40, 20), (90, 40, 30), (90, 40, 40), (90, 40, 50), (90, 40, 60), (90, 40, 70), (90, 40, 80), (90, 40, 90), (90, 50, 20), (90, 50, 30), (90, 50, 40), (90, 50, 50), (90, 50, 60), (90, 50, 70), (90, 50, 80), (90, 50, 90), (90, 60, 20), (90, 60, 30), (90, 60, 40), (90, 60, 50), (90, 60, 60), (90, 60, 70), (90, 60, 80), (90, 60, 90), (90, 70, 20), (90, 70, 30), (90, 70, 40), (90, 70, 50), (90, 70, 60), (90, 70, 70), (90, 70, 80), (90, 70, 90), (90, 80, 20), (90, 80, 30), (90, 80, 40), (90, 80, 50), (90, 80, 60), (90, 80, 70), (90, 80, 80), (90, 80, 90), (90, 90, 20), (90, 90, 30), (90, 90, 40), (90, 90, 50), (90, 90, 60), (90, 90, 70), (90, 90, 80), (90, 90, 90), (20, 2), (20, 3), (20, 4), (20, 5), (20, 6), (20, 7), (20, 8), (20, 9), (20, 10), (30, 2), (30, 3), (30, 4), (30, 5), (30, 6), (30, 7), (30, 8), (30, 9), (30, 10), (40, 2), (40, 3), (40, 4), (40, 5), (40, 6), (40, 7), (40, 8), (40, 9), (40, 10), (50, 2), (50, 3), (50, 4), (50, 5), (50, 6), (50, 7), (50, 8), (50, 9), (50, 10), (60, 2), (60, 3), (60, 4), (60, 5), (60, 6), (60, 7), (60, 8), (60, 9), (60, 10), (70, 2), (70, 3), (70, 4), (70, 5), (70, 6), (70, 7), (70, 8), (70, 9), (70, 10), (80, 2), (80, 3), (80, 4), (80, 5), (80, 6), (80, 7), (80, 8), (80, 9), (80, 10), (90, 2), (90, 3), (90, 4), (90, 5), (90, 6), (90, 7), (90, 8), (90, 9), (90, 10), (20, 2, 20), (20, 2, 30), (20, 2, 40), (20, 2, 50), (20, 2, 60), (20, 2, 70), (20, 2, 80), (20, 2, 90), (20, 3, 20), (20, 3, 30), (20, 3, 40), (20, 3, 50), (20, 3, 60), (20, 3, 70), (20, 3, 80), (20, 3, 90), (20, 4, 20), (20, 4, 30), (20, 4, 40), (20, 4, 50), (20, 4, 60), (20, 4, 70), (20, 4, 80), (20, 4, 90), (20, 5, 20), (20, 5, 30), (20, 5, 40), (20, 5, 50), (20, 5, 60), (20, 5, 70), (20, 5, 80), (20, 5, 90), (20, 6, 20), (20, 6, 30), (20, 6, 40), (20, 6, 50), (20, 6, 60), (20, 6, 70), (20, 6, 80), (20, 6, 90), (20, 7, 20), (20, 7, 30), (20, 7, 40), (20, 7, 50), (20, 7, 60), (20, 7, 70), (20, 7, 80), (20, 7, 90), (20, 8, 20), (20, 8, 30), (20, 8, 40), (20, 8, 50), (20, 8, 60), (20, 8, 70), (20, 8, 80), (20, 8, 90), (20, 9, 20), (20, 9, 30), (20, 9, 40), (20, 9, 50), (20, 9, 60), (20, 9, 70), (20, 9, 80), (20, 9, 90), (20, 10, 20), (20, 10, 30), (20, 10, 40), (20, 10, 50), (20, 10, 60), (20, 10, 70), (20, 10, 80), (20, 10, 90), (30, 2, 20), (30, 2, 30), (30, 2, 40), (30, 2, 50), (30, 2, 60), (30, 2, 70), (30, 2, 80), (30, 2, 90), (30, 3, 20), (30, 3, 30), (30, 3, 40), (30, 3, 50), (30, 3, 60), (30, 3, 70), (30, 3, 80), (30, 3, 90), (30, 4, 20), (30, 4, 30), (30, 4, 40), (30, 4, 50), (30, 4, 60), (30, 4, 70), (30, 4, 80), (30, 4, 90), (30, 5, 20), (30, 5, 30), (30, 5, 40), (30, 5, 50), (30, 5, 60), (30, 5, 70), (30, 5, 80), (30, 5, 90), (30, 6, 20), (30, 6, 30), (30, 6, 40), (30, 6, 50), (30, 6, 60), (30, 6, 70), (30, 6, 80), (30, 6, 90), (30, 7, 20), (30, 7, 30), (30, 7, 40), (30, 7, 50), (30, 7, 60), (30, 7, 70), (30, 7, 80), (30, 7, 90), (30, 8, 20), (30, 8, 30), (30, 8, 40), (30, 8, 50), (30, 8, 60), (30, 8, 70), (30, 8, 80), (30, 8, 90), (30, 9, 20), (30, 9, 30), (30, 9, 40), (30, 9, 50), (30, 9, 60), (30, 9, 70), (30, 9, 80), (30, 9, 90), (30, 10, 20), (30, 10, 30), (30, 10, 40), (30, 10, 50), (30, 10, 60), (30, 10, 70), (30, 10, 80), (30, 10, 90), (40, 2, 20), (40, 2, 30), (40, 2, 40), (40, 2, 50), (40, 2, 60), (40, 2, 70), (40, 2, 80), (40, 2, 90), (40, 3, 20), (40, 3, 30), (40, 3, 40), (40, 3, 50), (40, 3, 60), (40, 3, 70), (40, 3, 80), (40, 3, 90), (40, 4, 20), (40, 4, 30), (40, 4, 40), (40, 4, 50), (40, 4, 60), (40, 4, 70), (40, 4, 80), (40, 4, 90), (40, 5, 20), (40, 5, 30), (40, 5, 40), (40, 5, 50), (40, 5, 60), (40, 5, 70), (40, 5, 80), (40, 5, 90), (40, 6, 20), (40, 6, 30), (40, 6, 40), (40, 6, 50), (40, 6, 60), (40, 6, 70), (40, 6, 80), (40, 6, 90), (40, 7, 20), (40, 7, 30), (40, 7, 40), (40, 7, 50), (40, 7, 60), (40, 7, 70), (40, 7, 80), (40, 7, 90), (40, 8, 20), (40, 8, 30), (40, 8, 40), (40, 8, 50), (40, 8, 60), (40, 8, 70), (40, 8, 80), (40, 8, 90), (40, 9, 20), (40, 9, 30), (40, 9, 40), (40, 9, 50), (40, 9, 60), (40, 9, 70), (40, 9, 80), (40, 9, 90), (40, 10, 20), (40, 10, 30), (40, 10, 40), (40, 10, 50), (40, 10, 60), (40, 10, 70), (40, 10, 80), (40, 10, 90), (50, 2, 20), (50, 2, 30), (50, 2, 40), (50, 2, 50), (50, 2, 60), (50, 2, 70), (50, 2, 80), (50, 2, 90), (50, 3, 20), (50, 3, 30), (50, 3, 40), (50, 3, 50), (50, 3, 60), (50, 3, 70), (50, 3, 80), (50, 3, 90), (50, 4, 20), (50, 4, 30), (50, 4, 40), (50, 4, 50), (50, 4, 60), (50, 4, 70), (50, 4, 80), (50, 4, 90), (50, 5, 20), (50, 5, 30), (50, 5, 40), (50, 5, 50), (50, 5, 60), (50, 5, 70), (50, 5, 80), (50, 5, 90), (50, 6, 20), (50, 6, 30), (50, 6, 40), (50, 6, 50), (50, 6, 60), (50, 6, 70), (50, 6, 80), (50, 6, 90), (50, 7, 20), (50, 7, 30), (50, 7, 40), (50, 7, 50), (50, 7, 60), (50, 7, 70), (50, 7, 80), (50, 7, 90), (50, 8, 20), (50, 8, 30), (50, 8, 40), (50, 8, 50), (50, 8, 60), (50, 8, 70), (50, 8, 80), (50, 8, 90), (50, 9, 20), (50, 9, 30), (50, 9, 40), (50, 9, 50), (50, 9, 60), (50, 9, 70), (50, 9, 80), (50, 9, 90), (50, 10, 20), (50, 10, 30), (50, 10, 40), (50, 10, 50), (50, 10, 60), (50, 10, 70), (50, 10, 80), (50, 10, 90), (60, 2, 20), (60, 2, 30), (60, 2, 40), (60, 2, 50), (60, 2, 60), (60, 2, 70), (60, 2, 80), (60, 2, 90), (60, 3, 20), (60, 3, 30), (60, 3, 40), (60, 3, 50), (60, 3, 60), (60, 3, 70), (60, 3, 80), (60, 3, 90), (60, 4, 20), (60, 4, 30), (60, 4, 40), (60, 4, 50), (60, 4, 60), (60, 4, 70), (60, 4, 80), (60, 4, 90), (60, 5, 20), (60, 5, 30), (60, 5, 40), (60, 5, 50), (60, 5, 60), (60, 5, 70), (60, 5, 80), (60, 5, 90), (60, 6, 20), (60, 6, 30), (60, 6, 40), (60, 6, 50), (60, 6, 60), (60, 6, 70), (60, 6, 80), (60, 6, 90), (60, 7, 20), (60, 7, 30), (60, 7, 40), (60, 7, 50), (60, 7, 60), (60, 7, 70), (60, 7, 80), (60, 7, 90), (60, 8, 20), (60, 8, 30), (60, 8, 40), (60, 8, 50), (60, 8, 60), (60, 8, 70), (60, 8, 80), (60, 8, 90), (60, 9, 20), (60, 9, 30), (60, 9, 40), (60, 9, 50), (60, 9, 60), (60, 9, 70), (60, 9, 80), (60, 9, 90), (60, 10, 20), (60, 10, 30), (60, 10, 40), (60, 10, 50), (60, 10, 60), (60, 10, 70), (60, 10, 80), (60, 10, 90), (70, 2, 20), (70, 2, 30), (70, 2, 40), (70, 2, 50), (70, 2, 60), (70, 2, 70), (70, 2, 80), (70, 2, 90), (70, 3, 20), (70, 3, 30), (70, 3, 40), (70, 3, 50), (70, 3, 60), (70, 3, 70), (70, 3, 80), (70, 3, 90), (70, 4, 20), (70, 4, 30), (70, 4, 40), (70, 4, 50), (70, 4, 60), (70, 4, 70), (70, 4, 80), (70, 4, 90), (70, 5, 20), (70, 5, 30), (70, 5, 40), (70, 5, 50), (70, 5, 60), (70, 5, 70), (70, 5, 80), (70, 5, 90), (70, 6, 20), (70, 6, 30), (70, 6, 40), (70, 6, 50), (70, 6, 60), (70, 6, 70), (70, 6, 80), (70, 6, 90), (70, 7, 20), (70, 7, 30), (70, 7, 40), (70, 7, 50), (70, 7, 60), (70, 7, 70), (70, 7, 80), (70, 7, 90), (70, 8, 20), (70, 8, 30), (70, 8, 40), (70, 8, 50), (70, 8, 60), (70, 8, 70), (70, 8, 80), (70, 8, 90), (70, 9, 20), (70, 9, 30), (70, 9, 40), (70, 9, 50), (70, 9, 60), (70, 9, 70), (70, 9, 80), (70, 9, 90), (70, 10, 20), (70, 10, 30), (70, 10, 40), (70, 10, 50), (70, 10, 60), (70, 10, 70), (70, 10, 80), (70, 10, 90), (80, 2, 20), (80, 2, 30), (80, 2, 40), (80, 2, 50), (80, 2, 60), (80, 2, 70), (80, 2, 80), (80, 2, 90), (80, 3, 20), (80, 3, 30), (80, 3, 40), (80, 3, 50), (80, 3, 60), (80, 3, 70), (80, 3, 80), (80, 3, 90), (80, 4, 20), (80, 4, 30), (80, 4, 40), (80, 4, 50), (80, 4, 60), (80, 4, 70), (80, 4, 80), (80, 4, 90), (80, 5, 20), (80, 5, 30), (80, 5, 40), (80, 5, 50), (80, 5, 60), (80, 5, 70), (80, 5, 80), (80, 5, 90), (80, 6, 20), (80, 6, 30), (80, 6, 40), (80, 6, 50), (80, 6, 60), (80, 6, 70), (80, 6, 80), (80, 6, 90), (80, 7, 20), (80, 7, 30), (80, 7, 40), (80, 7, 50), (80, 7, 60), (80, 7, 70), (80, 7, 80), (80, 7, 90), (80, 8, 20), (80, 8, 30), (80, 8, 40), (80, 8, 50), (80, 8, 60), (80, 8, 70), (80, 8, 80), (80, 8, 90), (80, 9, 20), (80, 9, 30), (80, 9, 40), (80, 9, 50), (80, 9, 60), (80, 9, 70), (80, 9, 80), (80, 9, 90), (80, 10, 20), (80, 10, 30), (80, 10, 40), (80, 10, 50), (80, 10, 60), (80, 10, 70), (80, 10, 80), (80, 10, 90), (90, 2, 20), (90, 2, 30), (90, 2, 40), (90, 2, 50), (90, 2, 60), (90, 2, 70), (90, 2, 80), (90, 2, 90), (90, 3, 20), (90, 3, 30), (90, 3, 40), (90, 3, 50), (90, 3, 60), (90, 3, 70), (90, 3, 80), (90, 3, 90), (90, 4, 20), (90, 4, 30), (90, 4, 40), (90, 4, 50), (90, 4, 60), (90, 4, 70), (90, 4, 80), (90, 4, 90), (90, 5, 20), (90, 5, 30), (90, 5, 40), (90, 5, 50), (90, 5, 60), (90, 5, 70), (90, 5, 80), (90, 5, 90), (90, 6, 20), (90, 6, 30), (90, 6, 40), (90, 6, 50), (90, 6, 60), (90, 6, 70), (90, 6, 80), (90, 6, 90), (90, 7, 20), (90, 7, 30), (90, 7, 40), (90, 7, 50), (90, 7, 60), (90, 7, 70), (90, 7, 80), (90, 7, 90), (90, 8, 20), (90, 8, 30), (90, 8, 40), (90, 8, 50), (90, 8, 60), (90, 8, 70), (90, 8, 80), (90, 8, 90), (90, 9, 20), (90, 9, 30), (90, 9, 40), (90, 9, 50), (90, 9, 60), (90, 9, 70), (90, 9, 80), (90, 9, 90), (90, 10, 20), (90, 10, 30), (90, 10, 40), (90, 10, 50), (90, 10, 60), (90, 10, 70), (90, 10, 80), (90, 10, 90), (200, 200), (200, 300), (200, 400), (200, 500), (200, 600), (200, 700), (200, 800), (200, 900), (300, 200), (300, 300), (300, 400), (300, 500), (300, 600), (300, 700), (300, 800), (300, 900), (400, 200), (400, 300), (400, 400), (400, 500), (400, 600), (400, 700), (400, 800), (400, 900), (500, 200), (500, 300), (500, 400), (500, 500), (500, 600), (500, 700), (500, 800), (500, 900), (600, 200), (600, 300), (600, 400), (600, 500), (600, 600), (600, 700), (600, 800), (600, 900), (700, 200), (700, 300), (700, 400), (700, 500), (700, 600), (700, 700), (700, 800), (700, 900), (800, 200), (800, 300), (800, 400), (800, 500), (800, 600), (800, 700), (800, 800), (800, 900), (900, 200), (900, 300), (900, 400), (900, 500), (900, 600), (900, 700), (900, 800), (900, 900), (200, 200, 200), (200, 200, 300), (200, 200, 400), (200, 200, 500), (200, 200, 600), (200, 200, 700), (200, 200, 800), (200, 200, 900), (200, 300, 200), (200, 300, 300), (200, 300, 400), (200, 300, 500), (200, 300, 600), (200, 300, 700), (200, 300, 800), (200, 300, 900), (200, 400, 200), (200, 400, 300), (200, 400, 400), (200, 400, 500), (200, 400, 600), (200, 400, 700), (200, 400, 800), (200, 400, 900), (200, 500, 200), (200, 500, 300), (200, 500, 400), (200, 500, 500), (200, 500, 600), (200, 500, 700), (200, 500, 800), (200, 500, 900), (200, 600, 200), (200, 600, 300), (200, 600, 400), (200, 600, 500), (200, 600, 600), (200, 600, 700), (200, 600, 800), (200, 600, 900), (200, 700, 200), (200, 700, 300), (200, 700, 400), (200, 700, 500), (200, 700, 600), (200, 700, 700), (200, 700, 800), (200, 700, 900), (200, 800, 200), (200, 800, 300), (200, 800, 400), (200, 800, 500), (200, 800, 600), (200, 800, 700), (200, 800, 800), (200, 800, 900), (200, 900, 200), (200, 900, 300), (200, 900, 400), (200, 900, 500), (200, 900, 600), (200, 900, 700), (200, 900, 800), (200, 900, 900), (300, 200, 200), (300, 200, 300), (300, 200, 400), (300, 200, 500), (300, 200, 600), (300, 200, 700), (300, 200, 800), (300, 200, 900), (300, 300, 200), (300, 300, 300), (300, 300, 400), (300, 300, 500), (300, 300, 600), (300, 300, 700), (300, 300, 800), (300, 300, 900), (300, 400, 200), (300, 400, 300), (300, 400, 400), (300, 400, 500), (300, 400, 600), (300, 400, 700), (300, 400, 800), (300, 400, 900), (300, 500, 200), (300, 500, 300), (300, 500, 400), (300, 500, 500), (300, 500, 600), (300, 500, 700), (300, 500, 800), (300, 500, 900), (300, 600, 200), (300, 600, 300), (300, 600, 400), (300, 600, 500), (300, 600, 600), (300, 600, 700), (300, 600, 800), (300, 600, 900), (300, 700, 200), (300, 700, 300), (300, 700, 400), (300, 700, 500), (300, 700, 600), (300, 700, 700), (300, 700, 800), (300, 700, 900), (300, 800, 200), (300, 800, 300), (300, 800, 400), (300, 800, 500), (300, 800, 600), (300, 800, 700), (300, 800, 800), (300, 800, 900), (300, 900, 200), (300, 900, 300), (300, 900, 400), (300, 900, 500), (300, 900, 600), (300, 900, 700), (300, 900, 800), (300, 900, 900), (400, 200, 200), (400, 200, 300), (400, 200, 400), (400, 200, 500), (400, 200, 600), (400, 200, 700), (400, 200, 800), (400, 200, 900), (400, 300, 200), (400, 300, 300), (400, 300, 400), (400, 300, 500), (400, 300, 600), (400, 300, 700), (400, 300, 800), (400, 300, 900), (400, 400, 200), (400, 400, 300), (400, 400, 400), (400, 400, 500), (400, 400, 600), (400, 400, 700), (400, 400, 800), (400, 400, 900), (400, 500, 200), (400, 500, 300), (400, 500, 400), (400, 500, 500), (400, 500, 600), (400, 500, 700), (400, 500, 800), (400, 500, 900), (400, 600, 200), (400, 600, 300), (400, 600, 400), (400, 600, 500), (400, 600, 600), (400, 600, 700), (400, 600, 800), (400, 600, 900), (400, 700, 200), (400, 700, 300), (400, 700, 400), (400, 700, 500), (400, 700, 600), (400, 700, 700), (400, 700, 800), (400, 700, 900), (400, 800, 200), (400, 800, 300), (400, 800, 400), (400, 800, 500), (400, 800, 600), (400, 800, 700), (400, 800, 800), (400, 800, 900), (400, 900, 200), (400, 900, 300), (400, 900, 400), (400, 900, 500), (400, 900, 600), (400, 900, 700), (400, 900, 800), (400, 900, 900), (500, 200, 200), (500, 200, 300), (500, 200, 400), (500, 200, 500), (500, 200, 600), (500, 200, 700), (500, 200, 800), (500, 200, 900), (500, 300, 200), (500, 300, 300), (500, 300, 400), (500, 300, 500), (500, 300, 600), (500, 300, 700), (500, 300, 800), (500, 300, 900), (500, 400, 200), (500, 400, 300), (500, 400, 400), (500, 400, 500), (500, 400, 600), (500, 400, 700), (500, 400, 800), (500, 400, 900), (500, 500, 200), (500, 500, 300), (500, 500, 400), (500, 500, 500), (500, 500, 600), (500, 500, 700), (500, 500, 800), (500, 500, 900), (500, 600, 200), (500, 600, 300), (500, 600, 400), (500, 600, 500), (500, 600, 600), (500, 600, 700), (500, 600, 800), (500, 600, 900), (500, 700, 200), (500, 700, 300), (500, 700, 400), (500, 700, 500), (500, 700, 600), (500, 700, 700), (500, 700, 800), (500, 700, 900), (500, 800, 200), (500, 800, 300), (500, 800, 400), (500, 800, 500), (500, 800, 600), (500, 800, 700), (500, 800, 800), (500, 800, 900), (500, 900, 200), (500, 900, 300), (500, 900, 400), (500, 900, 500), (500, 900, 600), (500, 900, 700), (500, 900, 800), (500, 900, 900), (600, 200, 200), (600, 200, 300), (600, 200, 400), (600, 200, 500), (600, 200, 600), (600, 200, 700), (600, 200, 800), (600, 200, 900), (600, 300, 200), (600, 300, 300), (600, 300, 400), (600, 300, 500), (600, 300, 600), (600, 300, 700), (600, 300, 800), (600, 300, 900), (600, 400, 200), (600, 400, 300), (600, 400, 400), (600, 400, 500), (600, 400, 600), (600, 400, 700), (600, 400, 800), (600, 400, 900), (600, 500, 200), (600, 500, 300), (600, 500, 400), (600, 500, 500), (600, 500, 600), (600, 500, 700), (600, 500, 800), (600, 500, 900), (600, 600, 200), (600, 600, 300), (600, 600, 400), (600, 600, 500), (600, 600, 600), (600, 600, 700), (600, 600, 800), (600, 600, 900), (600, 700, 200), (600, 700, 300), (600, 700, 400), (600, 700, 500), (600, 700, 600), (600, 700, 700), (600, 700, 800), (600, 700, 900), (600, 800, 200), (600, 800, 300), (600, 800, 400), (600, 800, 500), (600, 800, 600), (600, 800, 700), (600, 800, 800), (600, 800, 900), (600, 900, 200), (600, 900, 300), (600, 900, 400), (600, 900, 500), (600, 900, 600), (600, 900, 700), (600, 900, 800), (600, 900, 900), (700, 200, 200), (700, 200, 300), (700, 200, 400), (700, 200, 500), (700, 200, 600), (700, 200, 700), (700, 200, 800), (700, 200, 900), (700, 300, 200), (700, 300, 300), (700, 300, 400), (700, 300, 500), (700, 300, 600), (700, 300, 700), (700, 300, 800), (700, 300, 900), (700, 400, 200), (700, 400, 300), (700, 400, 400), (700, 400, 500), (700, 400, 600), (700, 400, 700), (700, 400, 800), (700, 400, 900), (700, 500, 200), (700, 500, 300), (700, 500, 400), (700, 500, 500), (700, 500, 600), (700, 500, 700), (700, 500, 800), (700, 500, 900), (700, 600, 200), (700, 600, 300), (700, 600, 400), (700, 600, 500), (700, 600, 600), (700, 600, 700), (700, 600, 800), (700, 600, 900), (700, 700, 200), (700, 700, 300), (700, 700, 400), (700, 700, 500), (700, 700, 600), (700, 700, 700), (700, 700, 800), (700, 700, 900), (700, 800, 200), (700, 800, 300), (700, 800, 400), (700, 800, 500), (700, 800, 600), (700, 800, 700), (700, 800, 800), (700, 800, 900), (700, 900, 200), (700, 900, 300), (700, 900, 400), (700, 900, 500), (700, 900, 600), (700, 900, 700), (700, 900, 800), (700, 900, 900), (800, 200, 200), (800, 200, 300), (800, 200, 400), (800, 200, 500), (800, 200, 600), (800, 200, 700), (800, 200, 800), (800, 200, 900), (800, 300, 200), (800, 300, 300), (800, 300, 400), (800, 300, 500), (800, 300, 600), (800, 300, 700), (800, 300, 800), (800, 300, 900), (800, 400, 200), (800, 400, 300), (800, 400, 400), (800, 400, 500), (800, 400, 600), (800, 400, 700), (800, 400, 800), (800, 400, 900), (800, 500, 200), (800, 500, 300), (800, 500, 400), (800, 500, 500), (800, 500, 600), (800, 500, 700), (800, 500, 800), (800, 500, 900), (800, 600, 200), (800, 600, 300), (800, 600, 400), (800, 600, 500), (800, 600, 600), (800, 600, 700), (800, 600, 800), (800, 600, 900), (800, 700, 200), (800, 700, 300), (800, 700, 400), (800, 700, 500), (800, 700, 600), (800, 700, 700), (800, 700, 800), (800, 700, 900), (800, 800, 200), (800, 800, 300), (800, 800, 400), (800, 800, 500), (800, 800, 600), (800, 800, 700), (800, 800, 800), (800, 800, 900), (800, 900, 200), (800, 900, 300), (800, 900, 400), (800, 900, 500), (800, 900, 600), (800, 900, 700), (800, 900, 800), (800, 900, 900), (900, 200, 200), (900, 200, 300), (900, 200, 400), (900, 200, 500), (900, 200, 600), (900, 200, 700), (900, 200, 800), (900, 200, 900), (900, 300, 200), (900, 300, 300), (900, 300, 400), (900, 300, 500), (900, 300, 600), (900, 300, 700), (900, 300, 800), (900, 300, 900), (900, 400, 200), (900, 400, 300), (900, 400, 400), (900, 400, 500), (900, 400, 600), (900, 400, 700), (900, 400, 800), (900, 400, 900), (900, 500, 200), (900, 500, 300), (900, 500, 400), (900, 500, 500), (900, 500, 600), (900, 500, 700), (900, 500, 800), (900, 500, 900), (900, 600, 200), (900, 600, 300), (900, 600, 400), (900, 600, 500), (900, 600, 600), (900, 600, 700), (900, 600, 800), (900, 600, 900), (900, 700, 200), (900, 700, 300), (900, 700, 400), (900, 700, 500), (900, 700, 600), (900, 700, 700), (900, 700, 800), (900, 700, 900), (900, 800, 200), (900, 800, 300), (900, 800, 400), (900, 800, 500), (900, 800, 600), (900, 800, 700), (900, 800, 800), (900, 800, 900), (900, 900, 200), (900, 900, 300), (900, 900, 400), (900, 900, 500), (900, 900, 600), (900, 900, 700), (900, 900, 800), (900, 900, 900)]\n"
     ]
    }
   ],
   "source": [
    "# hiddenlayer_sizes = ((2,2),(2,3),(2,4),(2,5),(2,6),(2,7),(2,8),(2,9),(2,10)\n",
    "#                      ,(3,2),(3,3),(3,4),(3,5),(3,6),(3,7),(3,8),(3,9),(3,10),(3,10),\n",
    "\n",
    "randomtuple = []\n",
    "for i in range(2,11):\n",
    "    for j in range(2,11):\n",
    "        randomtuple.append((i,j))\n",
    "for i in range(2,11):\n",
    "    for j in range(2,11):\n",
    "        for ij in range(2,11):\n",
    "            randomtuple.append((i,j,ij))\n",
    "\n",
    "            \n",
    "            \n",
    "for i in range(20,100,10):\n",
    "    for j in range(20,100,10):\n",
    "        randomtuple.append((i,j))\n",
    "for i in range(20,100,10):\n",
    "    for j in range(20,100,10):\n",
    "        for ij in range(20,100,10):\n",
    "            randomtuple.append((i,j,ij))\n",
    "            \n",
    "            \n",
    "for i in range(20,100,10):\n",
    "    for j in range(2,11):\n",
    "        randomtuple.append((i,j))\n",
    "for i in range(20,100,10):\n",
    "    for j in range(2,11):\n",
    "        for ij in range(20,100,10):\n",
    "            randomtuple.append((i,j,ij))\n",
    "\n",
    "\n",
    "for i in range(200,1000,100):\n",
    "    for j in range(200,1000,100):\n",
    "        randomtuple.append((i,j))\n",
    "for i in range(200,1000,100):\n",
    "    for j in range(200,1000,100):\n",
    "        for ij in range(200,1000,100):\n",
    "            randomtuple.append((i,j,ij))\n",
    "\n",
    "\n",
    "    \n",
    "print(randomtuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2610"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(randomtuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "parameters = {\"activation\":[\"relu\"],\n",
    "              \"solver\":[\"sgd\",'lbfgs','adam'],\n",
    "              'alpha':[ 0.0001,0.001,0.01,0.1,1],\n",
    "              'hidden_layer_sizes': randomtuple}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lista' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-10ef151d0c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"hidden_layer_sizes\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlista\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lista' is not defined"
     ]
    }
   ],
   "source": [
    "# parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "parameters = { \"hidden_layer_sizes\": lista}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 39150 candidates, totalling 156600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 26.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18042 tasks      | elapsed: 61.2min\n",
      "[Parallel(n_jobs=-1)]: Done 19992 tasks      | elapsed: 66.9min\n",
      "[Parallel(n_jobs=-1)]: Done 22042 tasks      | elapsed: 73.1min\n",
      "[Parallel(n_jobs=-1)]: Done 24192 tasks      | elapsed: 80.3min\n",
      "[Parallel(n_jobs=-1)]: Done 26442 tasks      | elapsed: 323.1min\n",
      "[Parallel(n_jobs=-1)]: Done 28792 tasks      | elapsed: 741.4min\n",
      "[Parallel(n_jobs=-1)]: Done 31242 tasks      | elapsed: 1317.2min\n",
      "[Parallel(n_jobs=-1)]: Done 33792 tasks      | elapsed: 1353.0min\n",
      "[Parallel(n_jobs=-1)]: Done 36442 tasks      | elapsed: 1357.2min\n",
      "[Parallel(n_jobs=-1)]: Done 39192 tasks      | elapsed: 1362.1min\n",
      "[Parallel(n_jobs=-1)]: Done 42042 tasks      | elapsed: 1515.1min\n",
      "[Parallel(n_jobs=-1)]: Done 44992 tasks      | elapsed: 1533.6min\n",
      "[Parallel(n_jobs=-1)]: Done 48042 tasks      | elapsed: 1880.2min\n",
      "[Parallel(n_jobs=-1)]: Done 51192 tasks      | elapsed: 1890.0min\n",
      "[Parallel(n_jobs=-1)]: Done 54442 tasks      | elapsed: 1902.4min\n",
      "[Parallel(n_jobs=-1)]: Done 57792 tasks      | elapsed: 2159.2min\n",
      "[Parallel(n_jobs=-1)]: Done 61242 tasks      | elapsed: 2848.9min\n",
      "[Parallel(n_jobs=-1)]: Done 64792 tasks      | elapsed: 3257.4min\n",
      "[Parallel(n_jobs=-1)]: Done 68442 tasks      | elapsed: 3264.5min\n",
      "[Parallel(n_jobs=-1)]: Done 72192 tasks      | elapsed: 3274.0min\n",
      "[Parallel(n_jobs=-1)]: Done 76042 tasks      | elapsed: 3293.5min\n",
      "[Parallel(n_jobs=-1)]: Done 79992 tasks      | elapsed: 3319.5min\n",
      "[Parallel(n_jobs=-1)]: Done 84042 tasks      | elapsed: 3331.0min\n",
      "[Parallel(n_jobs=-1)]: Done 88192 tasks      | elapsed: 3469.6min\n",
      "[Parallel(n_jobs=-1)]: Done 92442 tasks      | elapsed: 4466.3min\n",
      "[Parallel(n_jobs=-1)]: Done 96792 tasks      | elapsed: 4948.1min\n",
      "[Parallel(n_jobs=-1)]: Done 101242 tasks      | elapsed: 4956.2min\n",
      "[Parallel(n_jobs=-1)]: Done 105792 tasks      | elapsed: 4970.3min\n",
      "[Parallel(n_jobs=-1)]: Done 110442 tasks      | elapsed: 4999.1min\n",
      "[Parallel(n_jobs=-1)]: Done 115192 tasks      | elapsed: 5013.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120042 tasks      | elapsed: 5284.0min\n",
      "[Parallel(n_jobs=-1)]: Done 124992 tasks      | elapsed: 6692.5min\n",
      "[Parallel(n_jobs=-1)]: Done 130042 tasks      | elapsed: 6847.7min\n",
      "[Parallel(n_jobs=-1)]: Done 135192 tasks      | elapsed: 6861.6min\n",
      "[Parallel(n_jobs=-1)]: Done 140442 tasks      | elapsed: 6910.5min\n",
      "[Parallel(n_jobs=-1)]: Done 145792 tasks      | elapsed: 6948.2min\n",
      "[Parallel(n_jobs=-1)]: Done 151242 tasks      | elapsed: 7316.1min\n",
      "[Parallel(n_jobs=-1)]: Done 156600 out of 156600 | elapsed: 9231.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.65236129\n",
      "Iteration 2, loss = 0.51900746\n",
      "Iteration 3, loss = 0.40774151\n",
      "Iteration 4, loss = 0.32511270\n",
      "Iteration 5, loss = 0.28363106\n",
      "Iteration 6, loss = 0.26755850\n",
      "Iteration 7, loss = 0.25898375\n",
      "Iteration 8, loss = 0.25262389\n",
      "Iteration 9, loss = 0.24701404\n",
      "Iteration 10, loss = 0.24194556\n",
      "Iteration 11, loss = 0.23719070\n",
      "Iteration 12, loss = 0.23266830\n",
      "Iteration 13, loss = 0.22822422\n",
      "Iteration 14, loss = 0.22384522\n",
      "Iteration 15, loss = 0.21949203\n",
      "Iteration 16, loss = 0.21518738\n",
      "Iteration 17, loss = 0.21109680\n",
      "Iteration 18, loss = 0.20706760\n",
      "Iteration 19, loss = 0.20310060\n",
      "Iteration 20, loss = 0.19921892\n",
      "Iteration 21, loss = 0.19539584\n",
      "Iteration 22, loss = 0.19163298\n",
      "Iteration 23, loss = 0.18795533\n",
      "Iteration 24, loss = 0.18436237\n",
      "Iteration 25, loss = 0.18080239\n",
      "Iteration 26, loss = 0.17729892\n",
      "Iteration 27, loss = 0.17391860\n",
      "Iteration 28, loss = 0.17056342\n",
      "Iteration 29, loss = 0.16731880\n",
      "Iteration 30, loss = 0.16409444\n",
      "Iteration 31, loss = 0.16094637\n",
      "Iteration 32, loss = 0.15790495\n",
      "Iteration 33, loss = 0.15491911\n",
      "Iteration 34, loss = 0.15198054\n",
      "Iteration 35, loss = 0.14910664\n",
      "Iteration 36, loss = 0.14634034\n",
      "Iteration 37, loss = 0.14356917\n",
      "Iteration 38, loss = 0.14092380\n",
      "Iteration 39, loss = 0.13831820\n",
      "Iteration 40, loss = 0.13579123\n",
      "Iteration 41, loss = 0.13331143\n",
      "Iteration 42, loss = 0.13086872\n",
      "Iteration 43, loss = 0.12851633\n",
      "Iteration 44, loss = 0.12622844\n",
      "Iteration 45, loss = 0.12399827\n",
      "Iteration 46, loss = 0.12179213\n",
      "Iteration 47, loss = 0.11967641\n",
      "Iteration 48, loss = 0.11761490\n",
      "Iteration 49, loss = 0.11557869\n",
      "Iteration 50, loss = 0.11363879\n",
      "Iteration 51, loss = 0.11175313\n",
      "Iteration 52, loss = 0.10984961\n",
      "Iteration 53, loss = 0.10806765\n",
      "Iteration 54, loss = 0.10631637\n",
      "Iteration 55, loss = 0.10461114\n",
      "Iteration 56, loss = 0.10295880\n",
      "Iteration 57, loss = 0.10135175\n",
      "Iteration 58, loss = 0.09979146\n",
      "Iteration 59, loss = 0.09826966\n",
      "Iteration 60, loss = 0.09679766\n",
      "Iteration 61, loss = 0.09538415\n",
      "Iteration 62, loss = 0.09398330\n",
      "Iteration 63, loss = 0.09264741\n",
      "Iteration 64, loss = 0.09134935\n",
      "Iteration 65, loss = 0.09009576\n",
      "Iteration 66, loss = 0.08887797\n",
      "Iteration 67, loss = 0.08769371\n",
      "Iteration 68, loss = 0.08654087\n",
      "Iteration 69, loss = 0.08543782\n",
      "Iteration 70, loss = 0.08438339\n",
      "Iteration 71, loss = 0.08332679\n",
      "Iteration 72, loss = 0.08232694\n",
      "Iteration 73, loss = 0.08137220\n",
      "Iteration 74, loss = 0.08043846\n",
      "Iteration 75, loss = 0.07953717\n",
      "Iteration 76, loss = 0.07866664\n",
      "Iteration 77, loss = 0.07781592\n",
      "Iteration 78, loss = 0.07699980\n",
      "Iteration 79, loss = 0.07622989\n",
      "Iteration 80, loss = 0.07547442\n",
      "Iteration 81, loss = 0.07474493\n",
      "Iteration 82, loss = 0.07404451\n",
      "Iteration 83, loss = 0.07336326\n",
      "Iteration 84, loss = 0.07270929\n",
      "Iteration 85, loss = 0.07208377\n",
      "Iteration 86, loss = 0.07148690\n",
      "Iteration 87, loss = 0.07090038\n",
      "Iteration 88, loss = 0.07033685\n",
      "Iteration 89, loss = 0.06981040\n",
      "Iteration 90, loss = 0.06930037\n",
      "Iteration 91, loss = 0.06878641\n",
      "Iteration 92, loss = 0.06832813\n",
      "Iteration 93, loss = 0.06785102\n",
      "Iteration 94, loss = 0.06741997\n",
      "Iteration 95, loss = 0.06700155\n",
      "Iteration 96, loss = 0.06659391\n",
      "Iteration 97, loss = 0.06620717\n",
      "Iteration 98, loss = 0.06583475\n",
      "Iteration 99, loss = 0.06548147\n",
      "Iteration 100, loss = 0.06513570\n",
      "Iteration 101, loss = 0.06481375\n",
      "Iteration 102, loss = 0.06449415\n",
      "Iteration 103, loss = 0.06420248\n",
      "Iteration 104, loss = 0.06391856\n",
      "Iteration 105, loss = 0.06364519\n",
      "Iteration 106, loss = 0.06338094\n",
      "Iteration 107, loss = 0.06312542\n",
      "Iteration 108, loss = 0.06289797\n",
      "Iteration 109, loss = 0.06266449\n",
      "Iteration 110, loss = 0.06245883\n",
      "Iteration 111, loss = 0.06223892\n",
      "Iteration 112, loss = 0.06204750\n",
      "Iteration 113, loss = 0.06186119\n",
      "Iteration 114, loss = 0.06168980\n",
      "Iteration 115, loss = 0.06150559\n",
      "Iteration 116, loss = 0.06135695\n",
      "Iteration 117, loss = 0.06118887\n",
      "Iteration 118, loss = 0.06104883\n",
      "Iteration 119, loss = 0.06091185\n",
      "Iteration 120, loss = 0.06077479\n",
      "Iteration 121, loss = 0.06065387\n",
      "Iteration 122, loss = 0.06053219\n",
      "Iteration 123, loss = 0.06041671\n",
      "Iteration 124, loss = 0.06031571\n",
      "Iteration 125, loss = 0.06020779\n",
      "Iteration 126, loss = 0.06011303\n",
      "Iteration 127, loss = 0.06002051\n",
      "Iteration 128, loss = 0.05993262\n",
      "Iteration 129, loss = 0.05985775\n",
      "Iteration 130, loss = 0.05976793\n",
      "Iteration 131, loss = 0.05970069\n",
      "Iteration 132, loss = 0.05963352\n",
      "Iteration 133, loss = 0.05956697\n",
      "Iteration 134, loss = 0.05949967\n",
      "Iteration 135, loss = 0.05944542\n",
      "Iteration 136, loss = 0.05938741\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10, 7, 2), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 4)\n",
    "\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "        estimator=MLPRegressor(verbose=1),\n",
    "        param_grid= parameters,\n",
    "        cv=tscv, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_result = gsc.fit(X_train, y_train)\n",
    "best_params = grid_result.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train:\n",
      "0.6017571842035909\n",
      "RMSE train:\n",
      "0.21595857860012374\n",
      "R2 test:\n",
      "-14.052429276024043\n",
      "RMSE test:\n",
      "0.25345202620166096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (30, 70, 20), 'random_state': 5, 'solver': 'adam'}\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam',random_state = 16)\n",
    "\n",
    "regressor.fit(X = X_train,y = y_train)\n",
    "y_pred= regressor.predict(X_train)\n",
    "\n",
    "print(\"R2 train:\")\n",
    "print(r2_score(y_train,y_pred))\n",
    "print(\"RMSE train:\")\n",
    "print(np.sqrt(mean_squared_error(y_train,y_pred)))\n",
    "y_pred = regressor.predict(X = X_test)\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross val r2: \n",
      "[-62.85745865 -11.08665358 -16.5010337  -12.64569187]\n",
      "Cross val r2 mean:\n",
      "-25.772709451819885\n",
      "\n",
      "\n",
      "Cross val RSME: \n",
      "[-0.53937677 -0.29439213 -0.35057161 -0.56487325]\n",
      "Cross val RSME mean: \n",
      "-0.43730343855595155\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam',random_state = 16)\n",
    "\n",
    "print(\"Cross val r2: \")\n",
    "print(cross_val_score(regressor, X_train,y_train, cv = tscv, scoring = \"r2\"))\n",
    "\n",
    "print(\"Cross val r2 mean:\")\n",
    "print(cross_val_score(regressor, X_train,y_train, cv = tscv, scoring = \"r2\").mean())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Cross val RSME: \")\n",
    "print(cross_val_score(regressor, X_train,y_train, cv = tscv, scoring = \"neg_root_mean_squared_error\"))\n",
    "\n",
    "print(\"Cross val RSME mean: \")\n",
    "print(cross_val_score(regressor, X_train,y_train, cv = tscv, scoring = \"neg_root_mean_squared_error\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANDOM DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "allset = df.append(dftest)\n",
    "\n",
    "Xall = allset[[\"Social benefits\",\"Homeprice\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "yall = allset['Electionresult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xall, yall, test_size=0.33, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test:\n",
      "0.6059564218367498\n",
      "RMSE test:\n",
      "0.1935947013761893\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam', random_state = 16).fit(X_train,y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ABLLIMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Social Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test:\n",
      "-16.199461173586823\n",
      "RMSE test:\n",
      "0.2709255043914993\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "# display(df)\n",
    "X_train = df[[\"Homeprice\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_train = df[\"Electionresult\"]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test =  dftest[[\"Homeprice\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_test = dftest[\"Electionresult\"]\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam', random_state = 16).fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Homeprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test:\n",
      "-2.199834673381684\n",
      "RMSE test:\n",
      "0.11685740553405943\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "# display(df)\n",
    "X_train = df[[\"Social benefits\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_train = df[\"Electionresult\"]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test =  dftest[[\"Social benefits\",\"Income\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_test = dftest[\"Electionresult\"]\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam', random_state = 16).fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test:\n",
      "-12.919922807422545\n",
      "RMSE test:\n",
      "0.24373106338022982\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "# display(df)\n",
    "X_train = df[[\"Social benefits\",\"Homeprice\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_train = df[\"Electionresult\"]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test =  dftest[[\"Social benefits\",\"Homeprice\",\"Bankruptcy\",\"Laborforce\"]]\n",
    "y_test = dftest[\"Electionresult\"]\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam', random_state = 16).fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test:\n",
      "-5.7294053204824005\n",
      "RMSE test:\n",
      "0.16946531118058222\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "# display(df)\n",
    "X_train = df[[\"Social benefits\",\"Homeprice\",\"Income\",\"Laborforce\"]]\n",
    "y_train = df[\"Electionresult\"]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test =  dftest[[\"Social benefits\",\"Homeprice\",\"Income\",\"Laborforce\"]]\n",
    "y_test = dftest[\"Electionresult\"]\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam', random_state = 16).fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Laborforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test:\n",
      "-39.74712222398103\n",
      "RMSE test:\n",
      "0.41700469131915263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "# display(df)\n",
    "X_train = df[[\"Social benefits\",\"Homeprice\",\"Income\",\"Bankruptcy\"]]\n",
    "y_train = df[\"Electionresult\"]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test =  dftest[[\"Social benefits\",\"Homeprice\",\"Income\",\"Bankruptcy\"]]\n",
    "y_test = dftest[\"Electionresult\"]\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "regressor = MLPRegressor(activation= 'relu', alpha= 0.0001, hidden_layer_sizes= (10,7,2), solver= 'adam', random_state = 16).fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print(\"R2 test:\")\n",
    "print(r2_score(y_test,y_pred))\n",
    "print(\"RMSE test:\")\n",
    "print(np.sqrt(mean_squared_error(y_test,y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation 9802 \n",
      " Population            0.115635\n",
      "Immigrants            0.249250\n",
      "Social benefits       0.224438\n",
      "Homeprice             0.004733\n",
      "Income                0.011718\n",
      "Bankruptcy            0.182108\n",
      "Population Density    0.111368\n",
      "Unemployment          0.004909\n",
      "Laborforce            0.112679\n",
      "Name: Electionresult, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Correlation 0203\n",
      " Population            0.019629\n",
      "Immigrants            0.073199\n",
      "Social benefits       0.015978\n",
      "Homeprice             0.090193\n",
      "Income                0.023677\n",
      "Bankruptcy            0.373962\n",
      "Population Density    0.109471\n",
      "Unemployment          0.311216\n",
      "Laborforce            0.103227\n",
      "Name: Electionresult, dtype: float64\n",
      "\n",
      "\n",
      "Correlation 0306\n",
      " Population            0.138574\n",
      "Immigrants            0.059725\n",
      "Social benefits       0.267810\n",
      "Homeprice             0.126453\n",
      "Income                0.110443\n",
      "Bankruptcy            0.001259\n",
      "Population Density    0.161016\n",
      "Unemployment          0.110266\n",
      "Laborforce            0.044399\n",
      "Name: Electionresult, dtype: float64\n",
      "\n",
      "\n",
      "Correlation 0610\n",
      " Population            0.259081\n",
      "Immigrants            0.294234\n",
      "Social benefits       0.306099\n",
      "Homeprice             0.029282\n",
      "Income                0.029670\n",
      "Bankruptcy            0.322135\n",
      "Population Density    0.488378\n",
      "Unemployment          0.110434\n",
      "Laborforce            0.006151\n",
      "Name: Electionresult, dtype: float64\n",
      "\n",
      "\n",
      "Correlation 1012\n",
      " Population            0.019674\n",
      "Immigrants            0.233850\n",
      "Social benefits       0.047193\n",
      "Homeprice             0.003634\n",
      "Income                0.033074\n",
      "Bankruptcy            0.081431\n",
      "Population Density    0.320509\n",
      "Unemployment          0.271315\n",
      "Laborforce            0.016258\n",
      "Name: Electionresult, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = df9802.corr()[\"Electionresult\"][df9802.corr()[\"Electionresult\"]<1].abs()\n",
    "print(\"Correlation 9802\",\"\\n\",corr)\n",
    "print(\"\\n\")\n",
    "corr = df0203.corr()[\"Electionresult\"][df0203.corr()[\"Electionresult\"]<1].abs()\n",
    "print(\"\\n\")\n",
    "print(\"Correlation 0203\\n\",corr)\n",
    "\n",
    "corr = df0306.corr()[\"Electionresult\"][df0306.corr()[\"Electionresult\"]<1].abs()\n",
    "print(\"\\n\")\n",
    "print(\"Correlation 0306\\n\",corr)\n",
    "corr = df0610.corr()[\"Electionresult\"][df0610.corr()[\"Electionresult\"]<1].abs()\n",
    "print(\"\\n\")\n",
    "print(\"Correlation 0610\\n\",corr)\n",
    "\n",
    "corr = df1012.corr()[\"Electionresult\"][df1012.corr()[\"Electionresult\"]<1].abs()\n",
    "print(\"\\n\")\n",
    "print(\"Correlation 1012\\n\",corr)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    356.000000\n",
       "mean      -0.197496\n",
       "std        0.065419\n",
       "min       -0.718100\n",
       "25%       -0.227721\n",
       "50%       -0.194941\n",
       "75%       -0.161095\n",
       "max        0.040451\n",
       "Name: Electionresult, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest['Electionresult'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Social benefits</th>\n",
       "      <th>Homeprice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Bankruptcy</th>\n",
       "      <th>Laborforce</th>\n",
       "      <th>Electionresult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "      <td>2136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.670538</td>\n",
       "      <td>5.491542</td>\n",
       "      <td>1.268832</td>\n",
       "      <td>10.365380</td>\n",
       "      <td>1.085227</td>\n",
       "      <td>-0.143264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.022880</td>\n",
       "      <td>10.640394</td>\n",
       "      <td>4.833615</td>\n",
       "      <td>18.115246</td>\n",
       "      <td>2.119583</td>\n",
       "      <td>0.314543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-18.854648</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>-80.316880</td>\n",
       "      <td>-17.991682</td>\n",
       "      <td>-9.090909</td>\n",
       "      <td>-0.720066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.353369</td>\n",
       "      <td>-1.713885</td>\n",
       "      <td>0.308287</td>\n",
       "      <td>-5.760288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.433613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.263185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.117504</td>\n",
       "      <td>13.698923</td>\n",
       "      <td>0.775310</td>\n",
       "      <td>-0.140287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.464935</td>\n",
       "      <td>15.562147</td>\n",
       "      <td>2.792429</td>\n",
       "      <td>21.382979</td>\n",
       "      <td>1.996687</td>\n",
       "      <td>0.040095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.667895</td>\n",
       "      <td>48.917749</td>\n",
       "      <td>8.804504</td>\n",
       "      <td>93.269231</td>\n",
       "      <td>11.822323</td>\n",
       "      <td>1.560556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Social benefits    Homeprice       Income   Bankruptcy   Laborforce  \\\n",
       "count      2136.000000  2136.000000  2136.000000  2136.000000  2136.000000   \n",
       "mean          0.670538     5.491542     1.268832    10.365380     1.085227   \n",
       "std           3.022880    10.640394     4.833615    18.115246     2.119583   \n",
       "min         -18.854648   -66.666667   -80.316880   -17.991682    -9.090909   \n",
       "25%          -1.353369    -1.713885     0.308287    -5.760288     0.000000   \n",
       "50%           0.263185     1.000000     2.117504    13.698923     0.775310   \n",
       "75%           2.464935    15.562147     2.792429    21.382979     1.996687   \n",
       "max          27.667895    48.917749     8.804504    93.269231    11.822323   \n",
       "\n",
       "       Electionresult  \n",
       "count     2136.000000  \n",
       "mean        -0.143264  \n",
       "std          0.314543  \n",
       "min         -0.720066  \n",
       "25%         -0.433613  \n",
       "50%         -0.140287  \n",
       "75%          0.040095  \n",
       "max          1.560556  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_Election.csv\", index_col = 0)\n",
    "dftest = pd.read_csv(\"/Users/ruben/Documents/Datascience & Society/Thesis/DFVariables_ElectionTEST.csv\", index_col = 0)\n",
    "allset = df.append(dftest)\n",
    "\n",
    "allset[[\"Social benefits\",\"Homeprice\",\"Income\",\"Bankruptcy\",\"Laborforce\",'Electionresult']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
